{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from heapq import nlargest\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Episode</th>\n",
       "      <th>Number of lines</th>\n",
       "      <th>Number of words</th>\n",
       "      <th>Different words used</th>\n",
       "      <th>Words per line</th>\n",
       "      <th>Different words ratio</th>\n",
       "      <th>Exclamation marks</th>\n",
       "      <th>Question marks</th>\n",
       "      <th>Word</th>\n",
       "      <th>Most common Monica</th>\n",
       "      <th>Most common Rachel</th>\n",
       "      <th>Most common Phoebe</th>\n",
       "      <th>Most common Chandler</th>\n",
       "      <th>Most common Ross</th>\n",
       "      <th>Most common Joey</th>\n",
       "      <th>Character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0101</td>\n",
       "      <td>49</td>\n",
       "      <td>554</td>\n",
       "      <td>277</td>\n",
       "      <td>11.3061</td>\n",
       "      <td>0.5</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rachel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0101</td>\n",
       "      <td>19</td>\n",
       "      <td>220</td>\n",
       "      <td>156</td>\n",
       "      <td>11.5789</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Phoebe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0101</td>\n",
       "      <td>39</td>\n",
       "      <td>350</td>\n",
       "      <td>212</td>\n",
       "      <td>8.97436</td>\n",
       "      <td>0.605714</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chandler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0101</td>\n",
       "      <td>47</td>\n",
       "      <td>449</td>\n",
       "      <td>265</td>\n",
       "      <td>9.55319</td>\n",
       "      <td>0.5902</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ross</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0101</td>\n",
       "      <td>41</td>\n",
       "      <td>394</td>\n",
       "      <td>232</td>\n",
       "      <td>9.60976</td>\n",
       "      <td>0.588832</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Joey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1369</td>\n",
       "      <td>1017-1018</td>\n",
       "      <td>85</td>\n",
       "      <td>712</td>\n",
       "      <td>332</td>\n",
       "      <td>8.37647</td>\n",
       "      <td>0.466292</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Phoebe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>1017-1018</td>\n",
       "      <td>83</td>\n",
       "      <td>642</td>\n",
       "      <td>301</td>\n",
       "      <td>7.73494</td>\n",
       "      <td>0.468847</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0124611</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chandler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1371</td>\n",
       "      <td>1017-1018</td>\n",
       "      <td>112</td>\n",
       "      <td>719</td>\n",
       "      <td>276</td>\n",
       "      <td>6.41964</td>\n",
       "      <td>0.383866</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0111266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ross</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1372</td>\n",
       "      <td>1017-1018</td>\n",
       "      <td>84</td>\n",
       "      <td>687</td>\n",
       "      <td>281</td>\n",
       "      <td>8.17857</td>\n",
       "      <td>0.409025</td>\n",
       "      <td>32</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0116448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Joey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1373</td>\n",
       "      <td>1017-1018</td>\n",
       "      <td>72</td>\n",
       "      <td>565</td>\n",
       "      <td>267</td>\n",
       "      <td>7.84722</td>\n",
       "      <td>0.472566</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0141593</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Monica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1374 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Episode Number of lines Number of words Different words used  \\\n",
       "0          0101              49             554                  277   \n",
       "1          0101              19             220                  156   \n",
       "2          0101              39             350                  212   \n",
       "3          0101              47             449                  265   \n",
       "4          0101              41             394                  232   \n",
       "...         ...             ...             ...                  ...   \n",
       "1369  1017-1018              85             712                  332   \n",
       "1370  1017-1018              83             642                  301   \n",
       "1371  1017-1018             112             719                  276   \n",
       "1372  1017-1018              84             687                  281   \n",
       "1373  1017-1018              72             565                  267   \n",
       "\n",
       "     Words per line Different words ratio Exclamation marks Question marks  \\\n",
       "0           11.3061                   0.5                28             16   \n",
       "1           11.5789              0.709091                 7              4   \n",
       "2           8.97436              0.605714                 9              8   \n",
       "3           9.55319                0.5902                14             21   \n",
       "4           9.60976              0.588832                20             16   \n",
       "...             ...                   ...               ...            ...   \n",
       "1369        8.37647              0.466292                40             33   \n",
       "1370        7.73494              0.468847                29             29   \n",
       "1371        6.41964              0.383866                36             37   \n",
       "1372        8.17857              0.409025                32             41   \n",
       "1373        7.84722              0.472566                33             16   \n",
       "\n",
       "     Word Most common Monica Most common Rachel Most common Phoebe  \\\n",
       "0       0                  0                  0                  0   \n",
       "1       0                  0                  0                  0   \n",
       "2       0                  0                  0                  0   \n",
       "3       0                  0                  0                  0   \n",
       "4       0                  0                  0                  0   \n",
       "...   ...                ...                ...                ...   \n",
       "1369    0                  0           0.011236                  0   \n",
       "1370    0                  0          0.0124611                  0   \n",
       "1371    0                  0          0.0111266                  0   \n",
       "1372    0                  0          0.0116448                  0   \n",
       "1373    0                  0          0.0141593                  0   \n",
       "\n",
       "     Most common Chandler Most common Ross Most common Joey Character  \n",
       "0                       0                0                0    Rachel  \n",
       "1                       0                0                0    Phoebe  \n",
       "2                       0                0                0  Chandler  \n",
       "3                       0                0                0      Ross  \n",
       "4                       0                0                0      Joey  \n",
       "...                   ...              ...              ...       ...  \n",
       "1369                    0                0                0    Phoebe  \n",
       "1370                    0                0                0  Chandler  \n",
       "1371                    0                0                0      Ross  \n",
       "1372                    0                0                0      Joey  \n",
       "1373                    0                0                0    Monica  \n",
       "\n",
       "[1374 rows x 16 columns]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_array = [] #append results to array to create data frame\n",
    "\n",
    "\n",
    "for filename in os.listdir('seasons/'):\n",
    "    \n",
    "    if filename.endswith(\".html\"):\n",
    "        \n",
    "        split_name = filename.split('.') #obtain the season and episodes\n",
    "        season = split_name[0]   \n",
    "        episode = split_name[1]\n",
    "\n",
    "        master_array.append([season, episode])\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "# Skapar nycklar till lexikon som sedan ska gÃ¶ras om till en dataframe\n",
    "numblines = dict()\n",
    "numblines[\"Episode\"] = []\n",
    "numblines[\"Number of lines\"] = []\n",
    "numblines[\"Number of words\"] = []\n",
    "numblines[\"Different words used\"] = []\n",
    "numblines[\"Words per line\"] = []\n",
    "numblines[\"Different words ratio\"] = []\n",
    "numblines[\"Exclamation marks\"] = []\n",
    "numblines[\"Question marks\"] = []\n",
    "numblines[\"Word\"] = []\n",
    "numblines[\"Most common Monica\"] = []\n",
    "numblines[\"Most common Rachel\"] = []\n",
    "numblines[\"Most common Phoebe\"] = []\n",
    "numblines[\"Most common Chandler\"] = []\n",
    "numblines[\"Most common Ross\"] = []\n",
    "numblines[\"Most common Joey\"] = []\n",
    "numblines[\"Character\"] = []\n",
    "    \n",
    "for num, ep in enumerate(master_array):\n",
    "\n",
    "    filename=master_array[num][0]+'.'+master_array[num][1]\n",
    "    f = open('seasons/'+filename, 'r')\n",
    "    data = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(data)\n",
    "    soup = soup.get_text().translate(str.maketrans({'\\n': ' ', '\\xa0': ''}))\n",
    "    pattern = re.compile(r'\\s(?=\\w+(?=:))') # store the regex\n",
    "    result = re.split(pattern, soup) # split the script where our pattern matched (pink dot)\n",
    "\n",
    "    # FÃ¶rdela datan i karaktÃ¤r och replik\n",
    "    episode_array = []\n",
    "    for item in result:\n",
    "        split_line = item.split(': ')\n",
    "        try:\n",
    "            character = split_line[0]\n",
    "            speech = split_line[1]\n",
    "            episode_array.append([character, speech])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    df = pd.DataFrame(episode_array, columns = ['Person','Said'])\n",
    "    df['Person'].replace({'CHAN':'Chandler','CHANDLER':'Chandler', 'Chandlers':'Chandler',\n",
    "                        'JOEY':'Joey',\n",
    "                        'MNCA':'Monica','MONICA':'Monica',\n",
    "                        'PHOE':'Phoebe','PHOEBE':'Phoebe', 'Pheebs':'Phoebe',\n",
    "                        'Rache':'Rachel','RACHEL':'Rachel', 'RACH':'Rachel',\n",
    "                        'ROSS':'Ross'},inplace=True)\n",
    "\n",
    "    \n",
    "    # Tar bort (), [], och \"[Scene\" frÃ¥n datan\n",
    "    curved = re.compile(\"(\\(.*?\\))\")\n",
    "    brackets = re.compile(\"(\\[.*?\\])\")\n",
    "    scene = re.compile(\"\\[Scene\")\n",
    "    for j,i in enumerate(df['Said']):\n",
    "        df.iloc[j][1] =re.sub(curved, '', i)\n",
    "\n",
    "    for j,i in enumerate(df['Said']):\n",
    "        df.iloc[j][1] =re.sub(brackets, '', i)\n",
    "        \n",
    "    for j,i in enumerate(df['Said']):\n",
    "        df.iloc[j][1] =re.sub(scene, '', i)\n",
    "\n",
    "    # Lista med unika ord samt antalet de sÃ¤gs\n",
    "    worddicts = {}\n",
    "    worddicts['Monica'] = {}\n",
    "    worddicts[\"Rachel\"]={}\n",
    "    worddicts[\"Phoebe\"]={}\n",
    "    worddicts[\"Chandler\"]={} \n",
    "    worddicts[\"Ross\"]={} \n",
    "    worddicts[\"Joey\"]={}\n",
    "    for i, j in enumerate(df[\"Person\"]):\n",
    "        if j in worddicts:\n",
    "            wordlist = Counter((x.rstrip(punctuation).lower() for x in df.iloc[i][1].split()))\n",
    "            for word in wordlist:\n",
    "                try:\n",
    "                    worddicts[j][word] = worddicts[j][word]+1\n",
    "                except KeyError:\n",
    "                    worddicts[j][word] = 1\n",
    "    \n",
    "    # Skapar dictionary fÃ¶r antal rader, frÃ¥getecken och utropstecken\n",
    "    namedict=dict()\n",
    "    namedict[\"Rachel\"]=[0]*3\n",
    "    namedict[\"Phoebe\"]=[0]*3\n",
    "    namedict[\"Chandler\"]=[0]*3\n",
    "    namedict[\"Ross\"]=[0]*3\n",
    "    namedict[\"Joey\"]=[0]*3\n",
    "    namedict[\"Monica\"]=[0]*3\n",
    "    \n",
    "    k = 0\n",
    "    for i in df[\"Person\"]:\n",
    "        if i in namedict:\n",
    "            try:\n",
    "                namedict[i][0] = namedict[i][0]+1\n",
    "                namedict[i][1] = namedict[i][1]+Counter(df.iloc[k][1])['!']\n",
    "                namedict[i][2] = namedict[i][2]+Counter(df.iloc[k][1])['?']\n",
    "            except:\n",
    "                pass\n",
    "        k = k+1\n",
    "    \n",
    "    # Ny kod fÃ¶r unika ord\n",
    "    ucommonwords = {}\n",
    "    ucommonwords['Monica']={}\n",
    "    ucommonwords[\"Rachel\"]={}\n",
    "    ucommonwords[\"Phoebe\"]={}\n",
    "    ucommonwords[\"Chandler\"]={} \n",
    "    ucommonwords[\"Ross\"]={} \n",
    "    ucommonwords[\"Joey\"]={}\n",
    "    for b in namedict:\n",
    "        for c in namedict:\n",
    "            ucommonwords[b][c] = 0\n",
    "            \n",
    "    for p in namedict:\n",
    "        for person in namedict:\n",
    "            for word in nlargest(30, worddicts[person], key=worddicts[person].get):\n",
    "\n",
    "                if word in uniqueWord[person]:\n",
    "                    try:\n",
    "                        ucommonwords[p][person] = ucommonwords[p][person]+worddicts[person][word]\n",
    "                    except:\n",
    "                        ucommonwords[p][person] = worddicts[p][word]\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "        try:\n",
    "            \n",
    "            numblines[\"Number of lines\"].append(namedict[p][0])\n",
    "            numblines[\"Character\"].append(p) \n",
    "            numblines[\"Episode\"].append(master_array[num][0])\n",
    "            #numblines[\"Most common 10\"].append(nlargest(10, worddicts[p], key=worddicts[p].get))\n",
    "            #numblines[\"Most common 30\"].append(nlargest(30, worddicts[p], key=worddicts[p].get))\n",
    "            #numblines[\"Most common 50\"].append(nlargest(50, worddicts[p], key=worddicts[p].get))\n",
    "            numblines[\"Number of words\"].append(sum(worddicts[p].values()))\n",
    "            numblines[\"Different words used\"].append(len(worddicts[p]))\n",
    "            numblines[\"Exclamation marks\"].append(namedict[p][1])\n",
    "            numblines[\"Question marks\"].append(namedict[p][2])\n",
    "            numblines[\"Words per line\"].append(sum(worddicts[p].values())/namedict[p][0])\n",
    "            numblines[\"Different words ratio\"].append(len(worddicts[p])/sum(worddicts[p].values()))\n",
    "            numblines[\"Most common Monica\"].append(ucommonwords[p][\"Monica\"]/sum(worddicts[p].values()))\n",
    "            numblines[\"Most common Rachel\"].append(ucommonwords[p][\"Rachel\"]/sum(worddicts[p].values()))\n",
    "            numblines[\"Most common Phoebe\"].append(ucommonwords[p][\"Phoebe\"]/sum(worddicts[p].values()))\n",
    "            numblines[\"Most common Chandler\"].append(ucommonwords[p][\"Chandler\"]/sum(worddicts[p].values()))\n",
    "            numblines[\"Most common Ross\"].append(ucommonwords[p][\"Ross\"]/sum(worddicts[p].values()))\n",
    "            numblines[\"Most common Joey\"].append(ucommonwords[p][\"Joey\"]/sum(worddicts[p].values()))\n",
    "            try:\n",
    "                numblines[\"Word\"].append(worddicts[p][\"smelly\"])\n",
    "            except:\n",
    "                numblines[\"Word\"].append(0)\n",
    "        except:\n",
    "               pass  \n",
    "        \n",
    "epinfo = pd.DataFrame.from_dict(numblines, orient='index')\n",
    "epinfo.transpose()\n",
    "    #plt.bar(list(namedict.keys()), namedict.values(), color='g')\n",
    "    #plt.show()\n",
    "#print(df.iloc[3][1])    \n",
    "#print(df.iloc[9][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most common words loop\n",
    "\n",
    "master_array = [] #append results to array to create data frame\n",
    "mostcommon = {}\n",
    "mostcommon[\"Monica\"] = {}\n",
    "mostcommon[\"Rachel\"] = {}\n",
    "mostcommon[\"Phoebe\"] = {}\n",
    "mostcommon[\"Chandler\"] = {}\n",
    "mostcommon[\"Ross\"] = {}\n",
    "mostcommon[\"Joey\"] = {}\n",
    "for filename in os.listdir('season/'):\n",
    "    if filename.endswith(\".html\"):\n",
    "        split_name = filename.split('.') #obtain the season and episodes\n",
    "        season = split_name[0]   \n",
    "        episode = split_name[1]\n",
    "\n",
    "        master_array.append([season, episode])\n",
    "    else:\n",
    "        pass\n",
    "for num, ep in enumerate(master_array):\n",
    "    filename=master_array[num][0]+'.'+master_array[num][1]\n",
    "\n",
    "    f = open('season/'+filename, 'r')\n",
    "    data = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(data)\n",
    "    readsoup = BeautifulSoup(data)\n",
    "\n",
    "    soup = soup.get_text().translate(str.maketrans({'\\n': ' ', '\\xa0': ''}))\n",
    "    pattern = re.compile(r'\\s(?=\\w+(?=:))') # store the regex\n",
    "    result = re.split(pattern, soup) # split the script where our pattern matched (pink dot)\n",
    "\n",
    "\n",
    "    episode_array=[]\n",
    "    for item in result:\n",
    "        split_line = item.split(': ')\n",
    "        try:\n",
    "            character = split_line[0]\n",
    "            speech = split_line[1]\n",
    "            episode_array.append([character, speech])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    df = pd.DataFrame(episode_array, columns = ['Person','Said'])\n",
    "\n",
    "    df['Person'].replace({'CHAN':'Chandler','CHANDLER':'Chandler', 'Chandlers':'Chandler',\n",
    "                        'JOEY':'Joey',\n",
    "                        'MNCA':'Monica','MONICA':'Monica',\n",
    "                        'PHOE':'Phoebe','PHOEBE':'Phoebe', 'Pheebs':'Phoebe',\n",
    "                        'Rache':'Rachel','RACHEL':'Rachel', 'RACH':'Rachel',\n",
    "                        'ROSS':'Ross'},inplace=True)\n",
    "\n",
    "    curved = re.compile(\"(\\(.*?\\))\")\n",
    "    brackets = re.compile(\"(\\[.*?\\])\")\n",
    "    scene = re.compile(\"\\[Scene\")\n",
    "    for j,i in enumerate(df['Said']):\n",
    "        df.iloc[j][1] =re.sub(curved, '', i)\n",
    "\n",
    "    for j,i in enumerate(df['Said']):\n",
    "        df.iloc[j][1] =re.sub(brackets, '', i)\n",
    "        \n",
    "    for j,i in enumerate(df['Said']):\n",
    "        df.iloc[j][1] =re.sub(scene, '', i)\n",
    "\n",
    "    worddicts = {}\n",
    "    worddicts['Monica'] = {}\n",
    "    worddicts[\"Rachel\"]={}\n",
    "    worddicts[\"Phoebe\"]={}\n",
    "    worddicts[\"Chandler\"]={} \n",
    "    worddicts[\"Ross\"]={} \n",
    "    worddicts[\"Joey\"]={}\n",
    "    for i, j in enumerate(df[\"Person\"]):\n",
    "        if j in worddicts:\n",
    "            wordlist = Counter((x.rstrip(punctuation).lower() for x in df.iloc[i][1].split()))\n",
    "            for word in wordlist:\n",
    "                try:\n",
    "                    worddicts[j][word] = worddicts[j][word]+1\n",
    "                except KeyError:\n",
    "                    worddicts[j][word] = 1\n",
    "                    \n",
    "    for p in namedict:\n",
    "        for key in worddicts[p].keys():\n",
    "            try:\n",
    "                mostcommon[p][key] = mostcommon[p][key]+worddicts[p][key]\n",
    "            except:\n",
    "                mostcommon[p][key] = worddicts[p][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commonloop ANVÃ„ND EJ\n",
    "    commonwords = {}\n",
    "    commonwords['Monica']={}\n",
    "    commonwords[\"Rachel\"]={}\n",
    "    commonwords[\"Phoebe\"]={}\n",
    "    commonwords[\"Chandler\"]={} \n",
    "    commonwords[\"Ross\"]={} \n",
    "    commonwords[\"Joey\"]={}\n",
    "    for b in namedict:\n",
    "        for c in namedict:\n",
    "            ucommonwords[b][c] = 0\n",
    "\n",
    "\n",
    "    for p in namedict:\n",
    "        for person in namedict:\n",
    "            for word in nlargest(30, worddicts[person], key=worddicts[person].get):\n",
    "                if word in nlargest(30, mostcommon[p], key=mostcommon[p].get):\n",
    "                    try:\n",
    "                        commonwords[p][person] = commonwords[p][person]+worddicts[person][word]\n",
    "                    except:\n",
    "                        commonwords[p][person] = worddicts[p][word]\n",
    "                else:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ANVÃ„ND EJ\n",
    "import itertools as it\n",
    "uniqueWord = {}\n",
    "uniqueWord[\"Monica\"] = {}\n",
    "uniqueWord[\"Rachel\"] = {}\n",
    "uniqueWord[\"Phoebe\"] = {}\n",
    "uniqueWord[\"Chandler\"] = {}\n",
    "uniqueWord[\"Ross\"] = {}\n",
    "uniqueWord[\"Joey\"] = {}\n",
    "numberOfWords = 2\n",
    "\n",
    "for person in worddicts:\n",
    "    per = [person]\n",
    "    \n",
    "    # Creates a list with all peoples words except from \"person\"\n",
    "    tempExclusive = list(it.chain.from_iterable([list(mostcommon[i].keys()) for i in list(worddicts.keys()) if i not in per]))\n",
    "    uniqueWord[person] = dict([(i, mostcommon[person][i]) for i in mostcommon[person] if i not in tempExclusive])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "uniqueWord = {}\n",
    "uniqueWord[\"Monica\"] = {}\n",
    "uniqueWord[\"Rachel\"] = {}\n",
    "uniqueWord[\"Phoebe\"] = {}\n",
    "uniqueWord[\"Chandler\"] = {}\n",
    "uniqueWord[\"Ross\"] = {}\n",
    "uniqueWord[\"Joey\"] = {}\n",
    "numberOfWords = 30 # Antalet ord i listan \"n\"\n",
    "mult = 2 # \n",
    "\n",
    "\n",
    "for person in worddicts:\n",
    "    \n",
    "    more = 0\n",
    "    \n",
    "    while len(uniqueWord[person]) < numberOfWords:\n",
    "        \n",
    "        per = [person]\n",
    "        # Skapar en lista med personens more + n-mest populÃ¤ra ord\n",
    "        personTop = nlargest(numberOfWords+more, mostcommon[person], key=mostcommon[person].get)\n",
    "        \n",
    "        # Skapar en lista med Ã¶vriga karaktÃ¤rers n*mult + more populÃ¤ra ord\n",
    "        tempExclusive = set(it.chain.from_iterable([nlargest((mult*numberOfWords)+more, mostcommon[i], key=mostcommon[i].get) for i in list(worddicts.keys()) if i not in per]))\n",
    "        tempExclusive = list(tempExclusive)\n",
    "        \n",
    "        # Plockar ut de ord som endast Ã¥terfinnes i personTop, ej tempExclusive\n",
    "        uniqueWord[person] = dict([(i, mostcommon[person][i]) for i in personTop if i not in tempExclusive])\n",
    "        \n",
    "        # UtÃ¶ka listan med ett element\n",
    "        more +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26811594202898553\n",
      "Character  Chandler  Joey  Monica  Phoebe  Rachel  Ross\n",
      "row_0                                                  \n",
      "Chandler          9     4       6       1       8    10\n",
      "Joey              2     2       4       4       4     5\n",
      "Monica            4     1       2       1       2     0\n",
      "Phoebe            5     2       6      13       6     5\n",
      "Rachel            2     2       3       2       7     1\n",
      "Ross              5     2       1       2       1     4\n"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model as skl_lm\n",
    "import sklearn.model_selection as skl_ms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.discriminant_analysis as skl_da\n",
    "import sklearn.preprocessing as skl_pre\n",
    "import math\n",
    "#epinfo = pd.read_csv('epinfo.csv')\n",
    "epinfo = epinfo.transpose()\n",
    "features = [#'Episode', \n",
    "            'Number of lines', \n",
    "            'Number of words', \n",
    "            'Different words used',\n",
    "            'Words per line', \n",
    "            'Different words ratio',\n",
    "            'Exclamation marks', \n",
    "            'Question marks', \n",
    "            'Word',\n",
    "            \"Most common Monica\",\n",
    "            \"Most common Rachel\",\n",
    "            \"Most common Phoebe\",\n",
    "            \"Most common Chandler\",\n",
    "            \"Most common Ross\",\n",
    "            \"Most common Joey\",\n",
    "            #'Most common 10',\n",
    "            #'Most common 30', \n",
    "            #'Most common 50', \n",
    "             ]\n",
    "#encode = ['Most common 10',\n",
    "#            'Most common 30', \n",
    "#            'Most common 50', \n",
    "#            ]\n",
    "X = epinfo[list(features)]\n",
    "#X2 = epinfo[list(encode)]\n",
    "#scaler = skl_pre.LabelEncoder.fit(X2)\n",
    "#X = X1 + scaler.transform(X2)\n",
    "Y = epinfo['Character']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = skl_ms.train_test_split(X,Y, test_size = 0.1)\n",
    "\n",
    "model = skl_lm.LogisticRegression(solver='newton-cg', multi_class='multinomial', max_iter=10000, \n",
    "                                  penalty='l2', fit_intercept = False)\n",
    "#model = skl_da.QuadraticDiscriminantAnalysis()\n",
    "model.fit(X_train, Y_train)\n",
    "prediction = model.predict(X_test)\n",
    "Y_hat = model.predict(X)\n",
    "print(np.mean(prediction==Y_test))\n",
    "print(pd.crosstab(prediction, Y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
