{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Import all modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import heapq\n",
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup as htmltotxt\n",
    "\n",
    "import sklearn.preprocessing as skl_pre\n",
    "import sklearn.linear_model as skl_lm\n",
    "import sklearn.discriminant_analysis as skl_da\n",
    "import sklearn.neighbors as skl_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Creates dataframe with features\n",
    "\n",
    "#master_array = [] #append results to array to create data frame\n",
    "#for filename in os.listdir('season/'):\n",
    "#  split_name = filename.split('.') #obtain the season and episodes\n",
    "#  season = split_name[0]   \n",
    "#  episode = split_name[1]\n",
    "#  #TODO method to get each line of the script\n",
    "#  master_array.append([season, episode])\n",
    "master_dict = dict()\n",
    "feature_dict = dict()\n",
    "\n",
    "#top5monica = ['cooking','chandler?','work','joey','boots']\n",
    "#top5joey = ['dude','casting','chandler?','agent','director']\n",
    "#top5phoebe = ['la','massage','smelly','yay!','buffay']\n",
    "#top5rachel = ['mon','barry','joshua','plane','ugh!']\n",
    "#top5ross = ['julie','dude','mon','justjust','elizabeth']\n",
    "#top5chandler = ['tulsa','kathy','joe!','gym','ring!']\n",
    "\n",
    "single_words = [\"monica\",\"joey\",\"phoebe\",\"rachel\",\"ross\",\"chandler\",\"dude\",\"crazy\",\"bro\",\"mate\",\"trash\"] #bro, mate, trash = trash\n",
    "\n",
    "Features = [\"Number of lines\",\"Number of words\",\"Words per line\",\"Exclamation marks\",\"Question marks\",\"Character\",\n",
    "           \"unique_words\"]\n",
    "Features.extend(single_words)\n",
    "for feat in Features:\n",
    "    master_dict[feat] = []\n",
    "    feature_dict[feat] = 0\n",
    "\n",
    "chars = ['monica','joey','phoebe','rachel','ross','chandler']\n",
    "\n",
    "\n",
    "for filename in os.listdir('season/'):  \n",
    "    f = open('season/'+filename, 'r')\n",
    "\n",
    "    data = htmltotxt(f.read()).get_text() #reads f as html file and converts into txt\n",
    "    \n",
    "    name_dict = dict()\n",
    "    for char in chars:\n",
    "        name_dict[char] = feature_dict.copy()\n",
    "\n",
    "    pattern = re.compile(r'\\s(?=\\w+(?=:))') #store the regex\n",
    "    result = re.split(pattern, data) # split the script where our pattern matched (pink dot)\n",
    "\n",
    "    episode_array=[]\n",
    "    for item in result:\n",
    "        split_line = item.split(':')\n",
    "        try:\n",
    "            character = split_line[0]\n",
    "            speech = split_line[1]\n",
    "            episode_array.append([character, speech])\n",
    "        except:\n",
    "            pass\n",
    "    unique_words_char = {'monica': []\n",
    "              ,'joey': []\n",
    "              ,'phoebe': []\n",
    "              ,'rachel': []\n",
    "              ,'ross': []\n",
    "              ,'chandler':[]}\n",
    "    \n",
    "    i = 0\n",
    "    while(len(episode_array) > i):\n",
    "        if episode_array[i][0].lower() not in chars:\n",
    "            del episode_array[i]\n",
    "        else:\n",
    "            character =episode_array[i][0].lower()\n",
    "            sentence =episode_array[i][1].lower()\n",
    "            #episode_array[i][1] = re.sub('[()]', '', episode_array[i][1])\n",
    "            #episode_array[i][1] = re.sub('-[^-]+-', '', episode_array[i][1]) #removes everything within --        \n",
    "            sentence = sentence.replace(\"-\",\"\").replace(\"\\n\",\" \").replace(\"\\xa0\",\" \").replace(\",\",\"\").replace(\".\",\"\").replace(\":\",\"\").replace(\"'\",\"\").replace(\"opening credits\",\"\").replace(\"closing credits\",\"\").replace(\"ending credits\",\"\").replace(\"commercial break\",\"\").replace(\"\\x92\",\"\")\n",
    "            sentence = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", sentence) #removes everything withing () and []\n",
    "            sentence = re.sub('\\[.*', '', sentence)\n",
    "            sentence = re.sub('\\(.*', '', sentence)\n",
    "            sentence = sentence.strip()\n",
    "            if len(episode_array) == i+1: #last sentence\n",
    "                sentence = sentence[:len(sentence)-3] #delets \"end\" in the end\n",
    "                sentence = sentence.strip()\n",
    "\n",
    "            words = sentence.split()\n",
    "            \n",
    "            \n",
    "            \n",
    "            name_dict[character][\"Number of lines\"] +=1\n",
    "            name_dict[character][\"Number of words\"] +=len(words)\n",
    "            name_dict[character][\"Exclamation marks\"] += sentence.count('!')\n",
    "            name_dict[character][\"Question marks\"] += sentence.count('?')\n",
    "            \n",
    "            episode_array[i][1].replace('chan','chandler').replace('chandlers','chandler').replace('mnca','monica').replace('phoe','phoebe').replace('pheebs','phoebe').replace('rache','rachel').replace('rach','rachel')\n",
    "            for word in words:\n",
    "                if word not in unique_words_char[character]:\n",
    "                    unique_words_char[character].append(word)\n",
    "            \n",
    "            for single_word in single_words:\n",
    "                name_dict[character][single_word] += sentence.count(single_word)\n",
    "            \n",
    "                \n",
    "            i +=1\n",
    "    for char in chars:\n",
    "        if name_dict[char][\"Number of lines\"] != 0:\n",
    "            name_dict[char][\"Words per line\"] = name_dict[char][\"Number of words\"]/name_dict[char][\"Number of lines\"]\n",
    "\n",
    "        master_dict[\"Number of lines\"].append(name_dict[char][\"Number of lines\"])\n",
    "        master_dict[\"Number of words\"].append(name_dict[char][\"Number of words\"])\n",
    "        master_dict[\"Words per line\"].append(name_dict[char][\"Words per line\"])\n",
    "        master_dict[\"Exclamation marks\"].append(name_dict[char][\"Exclamation marks\"])\n",
    "        master_dict[\"Question marks\"].append(name_dict[char][\"Question marks\"])\n",
    "        master_dict[\"Character\"].append(char)\n",
    "        master_dict[\"unique_words\"].append(len(unique_words_char[char]))\n",
    "        for single_word in single_words:\n",
    "            master_dict[single_word].append(name_dict[char][single_word])\n",
    "        \n",
    "        \n",
    "        #master_dict[\"top5monica\"].append(name_dict[j][\"top5monica\"])\n",
    "        #master_dict[\"top5joey\"].append(name_dict[j][\"top5joey\"])\n",
    "        #master_dict[\"top5phoebe\"].append(name_dict[j][\"top5phoebe\"])\n",
    "        #master_dict[\"top5rachel\"].append(name_dict[j][\"top5rachel\"])\n",
    "        #master_dict[\"top5ross\"].append(name_dict[j][\"top5ross\"])\n",
    "        #master_dict[\"top5chandler\"].append(name_dict[j][\"top5chandler\"])\n",
    "\n",
    "#print(master_dict)\n",
    "\n",
    "epinfo = pd.DataFrame.from_dict(master_dict, orient='index')\n",
    "epinfo.transpose().to_csv('epinfo.csv', index=False)        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40875912408759124\n",
      "0.32116788321167883\n",
      "0.39416058394160586\n",
      "0.4744525547445255\n",
      "0.4306569343065693\n",
      "0.43795620437956206\n",
      "0.36496350364963503\n",
      "0.3722627737226277\n",
      "0.39416058394160586\n",
      "0.35766423357664234\n",
      "0.41605839416058393\n",
      "0.41605839416058393\n",
      "0.36496350364963503\n",
      "0.40875912408759124\n",
      "0.41605839416058393\n",
      "0.43795620437956206\n",
      "0.38686131386861317\n",
      "0.46715328467153283\n",
      "0.4306569343065693\n",
      "0.41605839416058393\n",
      "Total average: 0.40583941605839424\n"
     ]
    }
   ],
   "source": [
    "###Train model\n",
    "url = 'epinfo.csv'\n",
    "data = pd.read_csv(url)\n",
    "#print(data)\n",
    "x = []\n",
    "loops = 20\n",
    "xtraintest = ['Number of lines','Number of words','Words per line','Exclamation marks','Question marks',\n",
    "                    'monica','joey','phoebe','rachel','ross','chandler','dude','crazy']\n",
    "model = skl_lm.LogisticRegression(solver = 'lbfgs', max_iter = 6000)\n",
    "for i in range(loops):\n",
    "\n",
    "    trainI = np.random.choice(data.shape[0], size = int(len(data)*.9), replace = False)\n",
    "    trainIndex = data.index.isin(trainI)\n",
    "    train = data.iloc[trainIndex] #training set\n",
    "    test = data.iloc[~trainIndex] #test set\n",
    "\n",
    "    #x='Number of lines','Number of words','Different words used','Words per line','Different words ratio','Exclamation marks','Question marks','Most common 10','Most common 30','Most common 50'\n",
    "    \n",
    "    X_train = train[xtraintest]\n",
    "    Y_train = train['Character']\n",
    "    X_test = test[xtraintest]\n",
    "    Y_test = test['Character']\n",
    "\n",
    "    model.fit(X_train,Y_train)\n",
    "\n",
    "    x.append(np.mean(model.predict(X_test) == Y_test))\n",
    "    print(x[i])\n",
    "\n",
    "xmean = np.mean(x)\n",
    "\n",
    "print(\"Total average:\",xmean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique words for characters\n",
    "\n",
    "#def Diff(li1, li2):\n",
    "#    li_dif = [i for i in li1 + li2 if i not in li1 or i not in li2]\n",
    "#    return li_dif\n",
    "\n",
    "commonwords = list(set(words_char['monica']) & set(words_char['joey']) & set(words_char['phoebe']) & set(words_char['rachel']) & set(words_char['ross']) & set(words_char['chandler']))\n",
    "#monicauniqeDiff(words_char['monica'], commonwords)\n",
    "monicaunique = list(set(words_char['chandler']).symmetric_difference(set(commonwords)))\n",
    "\n",
    "commonmonica = dict()\n",
    "for i in words_char['chandler']:\n",
    "    if i in monicaunique:\n",
    "        if i in commonmonica:\n",
    "            commonmonica[i] +=1\n",
    "        else:        \n",
    "            commonmonica[i] = 1\n",
    "commonmonica = sorted(commonmonica.items(), key=lambda item: item[1])\n",
    "\n",
    "top5monica = ['cooking','chandler?','work','joey','boots']\n",
    "top5joey = ['dude','casting','chandler?','agent','director']\n",
    "top5phoebe = ['la','massage','smelly','yay!','buffay']\n",
    "top5rachel = ['mon','barry','joshua','plane','ugh!']\n",
    "top5ross = ['julie','dude','mon','justjust','elizabeth']\n",
    "top5chandler = ['tulsa','kathy','joe!','gym','ring!']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number of lines           19\n",
       "Number of words          259\n",
       "Words per line       13.6316\n",
       "Exclamation marks          7\n",
       "Question marks             4\n",
       "Character             phoebe\n",
       "unique_words             157\n",
       "monica                     0\n",
       "joey                       0\n",
       "phoebe                     0\n",
       "rachel                     0\n",
       "ross                       0\n",
       "chandler                   0\n",
       "dude                       0\n",
       "crazy                      0\n",
       "bro                        0\n",
       "mate                       0\n",
       "trash                      0\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epinfo[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-a2a3199ad24e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mFeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Character'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
